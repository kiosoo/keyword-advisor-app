# -*- coding: utf-8 -*-
"""
CÃ”NG Cá»¤ Cá» Váº¤N Cá»¦A LÃ VÄ‚N HIá»†P(KIOSOO)
XÃ¢y dá»±ng báº±ng Streamlit.
"""
import streamlit as st
from pytrends.request import TrendReq
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LinearRegression
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import time
from requests.exceptions import ReadTimeout

# --- Dá»¯ liá»‡u tÄ©nh ---
COUNTRIES = {
    'Vietnam': 'VN', 'United States': 'US', 'Japan': 'JP', 'South Korea': 'KR',
    'United Kingdom': 'GB', 'Germany': 'DE', 'France': 'FR', 'Canada': 'CA',
    'Australia': 'AU', 'India': 'IN', 'Brazil': 'BR', 'Russia': 'RU',
    'Thailand': 'TH', 'Singapore': 'SG', 'Malaysia': 'MY',
    'Indonesia': 'ID', 'Philippines': 'PH', 'Taiwan': 'TW', 'Hong Kong': 'HK',
    'Spain': 'ES', 'Portugal': 'PT'
}
SORTED_COUNTRIES = dict(sorted(COUNTRIES.items()))

# --- Cáº¥u hÃ¬nh trang web ---
st.set_page_config(page_title="CÃ”NG Cá»¤ Cá» Váº¤N Cá»¦A LÃ VÄ‚N HIá»†P(KIOSOO)", page_icon="ğŸ§ ", layout="wide")

# --- Khá»Ÿi táº¡o Session State Ä‘á»ƒ quáº£n lÃ½ API Key ---
if 'youtube_key_index' not in st.session_state:
    st.session_state.youtube_key_index = 0

# --- CÃ¡c hÃ m tÃ­nh toÃ¡n vÃ  tiá»‡n Ã­ch ---
@st.cache_data(ttl=3600)
def analyze_trends_data(keywords, country_code, timeframe, gprop):
    """
    HÃ m Ä‘Æ°á»£c nÃ¢ng cáº¥p vá»›i logic tá»± Ä‘á»™ng thá»­ láº¡i (Exponential Backoff)
    """
    retries = 3
    delay = 1
    
    for i in range(retries):
        try:
            pytrends = TrendReq(hl='en-US', tz=360, timeout=(10, 25)) 
            pytrends.build_payload(kw_list=keywords, timeframe=timeframe, geo=country_code, gprop=gprop)
            
            interest_df = pytrends.interest_over_time()
            related_queries = pytrends.related_queries()

            if interest_df.empty:
                return None, None, "KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u."
            
            interest_df.drop(columns=['isPartial'], inplace=True, errors='ignore')
            return interest_df, related_queries, None

        except ReadTimeout:
             if i < retries - 1:
                st.toast(f"Google Trends pháº£n há»“i cháº­m, Ä‘ang thá»­ láº¡i láº§n {i+1}/{retries-1}...")
                time.sleep(delay)
                delay *= 2
             else:
                return None, None, "Lá»—i: Google Trends khÃ´ng pháº£n há»“i ká»‹p thá»i. Vui lÃ²ng thá»­ láº¡i sau."

        except Exception as e:
            if 'response with code 429' in str(e):
                if i < retries - 1:
                    st.toast(f"Bá»‹ giá»›i háº¡n truy cáº­p, Ä‘ang thá»­ láº¡i sau {delay} giÃ¢y...")
                    time.sleep(delay)
                    delay *= 2
                else:
                    return None, None, f"Lá»—i: Google Trends Ä‘ang táº¡m thá»i giá»›i háº¡n truy cáº­p. Vui lÃ²ng thá»­ láº¡i sau Ã­t phÃºt. (Code: 429)"
            else:
                return None, None, f"ÄÃ£ xáº£y ra lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}"
    
    return None, None, "ÄÃ£ thá»­ láº¡i nhiá»u láº§n nhÆ°ng khÃ´ng thÃ nh cÃ´ng."


def search_youtube_videos_with_rotation(query):
    api_keys_str = st.secrets.get("YOUTUBE_API_KEYS", "")
    if not api_keys_str:
        return None, "Lá»—i cáº¥u hÃ¬nh: Vui lÃ²ng thÃªm YOUTUBE_API_KEYS vÃ o Streamlit Secrets."
    
    api_keys = [key.strip() for key in api_keys_str.split(',')]
    start_index = st.session_state.youtube_key_index
    
    for i in range(len(api_keys)):
        current_key_index = (start_index + i) % len(api_keys)
        api_key = api_keys[current_key_index]
        
        try:
            youtube = build('youtube', 'v3', developerKey=api_key)
            request = youtube.search().list(q=query, part='snippet', maxResults=5, type='video', order='relevance')
            response = request.execute()
            st.session_state.youtube_key_index = (current_key_index + 1) % len(api_keys)
            videos = [{'id': item['id']['videoId'], 'title': item['snippet']['title'], 'channel': item['snippet']['channelTitle'], 'thumbnail': item['snippet']['thumbnails']['high']['url'], 'url': f'[https://www.youtube.com/watch?v=](https://www.youtube.com/watch?v=){item["id"]["videoId"]}'} for item in response.get('items', [])]
            return videos, None
        except HttpError as e:
            error_details = e.error_details
            is_quota_error = any(detail.get('reason') in ['quotaExceeded', 'dailyLimitExceeded'] for detail in error_details) if error_details else False
            if is_quota_error:
                print(f"Key {current_key_index + 1} Ä‘Ã£ háº¿t quota. Äang chuyá»ƒn sang key tiáº¿p theo...")
                continue
            else:
                return None, f"Lá»—i API vá»›i Key {current_key_index + 1}: {e}. Vui lÃ²ng kiá»ƒm tra láº¡i key."
        except Exception as e:
            return None, f"ÄÃ£ xáº£y ra lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}"
    return None, "Táº¥t cáº£ cÃ¡c API key Ä‘á»u Ä‘Ã£ háº¿t háº¡n ngáº¡ch hoáº·c khÃ´ng há»£p lá»‡."

def calculate_potential_score(interest_series, related_queries_data):
    if interest_series.empty or interest_series.sum() == 0:
        return {'score': 0, 'label': "KhÃ´ng cÃ³ dá»¯ liá»‡u", 'color': "#6c757d"}
    avg_interest = interest_series.mean()
    avg_interest_score = min((avg_interest / 80), 1) * 30 
    X = np.arange(len(interest_series)).reshape(-1, 1)
    y = interest_series.values
    model = LinearRegression().fit(X, y)
    slope = model.coef_[0]
    normalized_slope = (slope / (avg_interest + 1e-6)) * 100
    trend_score = 10 + normalized_slope
    trend_score = np.clip(trend_score, 0, 20)
    interest_score = avg_interest_score + trend_score
    growth_score = 0
    rising_df = related_queries_data.get('rising')
    if rising_df is not None and not rising_df.empty:
        def process_rising_value(val):
            if isinstance(val, str) and 'Breakout' in val: return 10000
            numeric_val = pd.to_numeric(str(val).replace('+','').replace('%','').replace(',',''), errors='coerce')
            return numeric_val if pd.notnull(numeric_val) else 0
        rising_df['value_numeric'] = rising_df['value'].apply(process_rising_value)
        num_rising_score = min(len(rising_df) / 10, 1) * 25
        avg_growth_score = min(rising_df['value_numeric'].mean() / 1000, 1) * 25
        growth_score = num_rising_score + avg_growth_score
    total_score = int(interest_score + growth_score)
    if total_score >= 70: label, color = 'Tiá»m nÄƒng cao', '#28a745'
    elif total_score >= 40: label, color = 'Trung bÃ¬nh', '#ffc107'
    else: label, color = 'BÃ£o hÃ²a / Cáº¡nh tranh cao', '#dc3545'
    return {'score': total_score, 'label': label, 'color': color, 'interest_score': interest_score, 'growth_score': growth_score, 'slope': slope, 'avg_interest': avg_interest, 'rising_df': rising_df}

def generate_advice(kw, metrics):
    score = metrics.get('score', 0)
    full_advice = {
        "gold": f"**ğŸŸ¢ ÄÃ‚Y LÃ€ Má»˜T CÆ  Há»˜I VÃ€NG!** Äiá»ƒm tiá»m nÄƒng cao cá»§a **'{kw}'** chá»§ yáº¿u Ä‘áº¿n tá»« **sá»± bÃ¹ng ná»• cá»§a cÃ¡c thá»‹ trÆ°á»ng ngÃ¡ch** liÃªn quan. Máº·c dÃ¹ chá»§ Ä‘á» chÃ­nh cÃ³ thá»ƒ chÆ°a pháº£i lá»›n nháº¥t, nhÆ°ng cÃ¡c truy váº¥n con Ä‘ang tÄƒng trÆ°á»Ÿng cá»±c ká»³ máº¡nh. \n\n**Chiáº¿n lÆ°á»£c:** **HÃ nh Ä‘á»™ng nhanh!** HÃ£y táº­p trung sáº£n xuáº¥t ná»™i dung xoay quanh cÃ¡c chá»§ Ä‘á» Ä‘ang 'nÃ³ng' trong báº£ng 'Truy váº¥n Ä‘ang tÄƒng trÆ°á»Ÿng' Ä‘á»ƒ Ä‘Ã³n Ä‘áº§u xu hÆ°á»›ng.",
        "popular": f"**ğŸŸ¢ CHá»¦ Äá»€ ÄANG Ráº¤T THá»ŠNH HÃ€NH!** **'{kw}'** Ä‘ang cÃ³ má»©c Ä‘á»™ quan tÃ¢m ráº¥t cao vÃ  á»•n Ä‘á»‹nh tá»« cá»™ng Ä‘á»“ng. ÄÃ¢y lÃ  má»™t chá»§ Ä‘á» lá»›n vá»›i lÆ°á»£ng khÃ¡n giáº£ dá»“i dÃ o. \n\n**Chiáº¿n lÆ°á»£c:** Cáº¡nh tranh sáº½ ráº¥t cao. Video cá»§a báº¡n cáº§n pháº£i **thá»±c sá»± ná»•i báº­t** vá» cháº¥t lÆ°á»£ng hoáº·c cÃ³ má»™t **gÃ³c nhÃ¬n Ä‘á»™c Ä‘Ã¡o** mÃ  chÆ°a ai khai thÃ¡c.",
        "sustainable": f"**ğŸŸ¡ CÆ  Há»˜I NGÃCH Bá»€N Vá»®NG.** **'{kw}'** lÃ  má»™t chá»§ Ä‘á» cÃ³ sá»± tÄƒng trÆ°á»Ÿng á»•n Ä‘á»‹nh nhÆ°ng khÃ´ng quÃ¡ bÃ¹ng ná»•. ÄÃ¢y lÃ  cÆ¡ há»™i tuyá»‡t vá»i Ä‘á»ƒ xÃ¢y dá»±ng ná»™i dung cháº¥t lÆ°á»£ng vÃ  thu hÃºt má»™t lÆ°á»£ng khÃ¡n giáº£ trung thÃ nh vá»›i má»©c Ä‘á»™ cáº¡nh tranh vá»«a pháº£i. \n\n**Chiáº¿n lÆ°á»£c:** Táº­p trung vÃ o viá»‡c **giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» cá»¥ thá»ƒ** cho khÃ¡n giáº£. HÃ£y xem báº£ng 'Truy váº¥n Ä‘ang tÄƒng trÆ°á»Ÿng' Ä‘á»ƒ tÃ¬m nhá»¯ng Ã½ tÆ°á»Ÿng video chi tiáº¿t.",
        "evergreen": f"**ğŸŸ¡ CHá»¦ Äá»€ 'EVERGREEN' Cáº¦N TÃŒM NGÃCH.** **'{kw}'** cÃ³ má»™t lÆ°á»£ng khÃ¡n giáº£ á»•n Ä‘á»‹nh nhÆ°ng khÃ´ng cÃ²n trong giai Ä‘oáº¡n tÄƒng trÆ°á»Ÿng. Äá»ƒ thÃ nh cÃ´ng, báº¡n khÃ´ng nÃªn lÃ m video chung chung. \n\n**Chiáº¿n lÆ°á»£c:** HÃ£y **Ä‘Ã o tháº­t sÃ¢u** vÃ o má»™t khÃ­a cáº¡nh ráº¥t nhá» cá»§a chá»§ Ä‘á» nÃ y. PhÃ¢n tÃ­ch báº£ng 'Truy váº¥n hÃ ng Ä‘áº§u' Ä‘á»ƒ hiá»ƒu khÃ¡n giáº£ Ä‘ang tÃ¬m kiáº¿m gÃ¬ vÃ  táº¡o ra ná»™i dung tá»‘t hÆ¡n cÃ¡c Ä‘á»‘i thá»§.",
        "saturated": f"**ğŸ”´ Cáº¨N TRá»ŒNG - THá»Š TRÆ¯á»œNG BÃƒO HÃ’A.** **'{kw}'** cÃ³ thá»ƒ cÃ³ lÆ°á»£ng tÃ¬m kiáº¿m cao, nhÆ°ng xu hÆ°á»›ng chung Ä‘ang giáº£m vÃ  khÃ´ng cÃ³ nhiá»u tÃ­n hiá»‡u tÄƒng trÆ°á»Ÿng má»›i. Cáº¡nh tranh trong chá»§ Ä‘á» nÃ y cá»±c ká»³ khá»‘c liá»‡t vá»›i nhiá»u kÃªnh lá»›n Ä‘Ã£ chiáº¿m lÄ©nh. \n\n**Chiáº¿n lÆ°á»£c:** **NÃªn trÃ¡nh** náº¿u báº¡n lÃ  ngÆ°á»i má»›i. Trá»« khi báº¡n cÃ³ má»™t Ã½ tÆ°á»Ÿng thá»±c sá»± Ä‘á»™t phÃ¡, thá»i gian cá»§a báº¡n nÃªn Ä‘Æ°á»£c Ä‘áº§u tÆ° vÃ o cÃ¡c chá»§ Ä‘á» tiá»m nÄƒng hÆ¡n.",
        "low_interest": f"**ğŸ”´ CHá»¦ Äá»€ ÃT QUAN TÃ‚M.** LÆ°á»£ng tÃ¬m kiáº¿m cho **'{kw}'** hiá»‡n táº¡i ráº¥t tháº¥p vÃ  khÃ´ng cÃ³ dáº¥u hiá»‡u tÄƒng trÆ°á»Ÿng. Sáº½ ráº¥t khÃ³ Ä‘á»ƒ xÃ¢y dá»±ng má»™t video thÃ nh cÃ´ng vá»›i chá»§ Ä‘á» nÃ y. \n\n**Chiáº¿n lÆ°á»£c:** HÃ£y sá»­ dá»¥ng cÃ´ng cá»¥ Ä‘á»ƒ tÃ¬m kiáº¿m cÃ¡c tá»« khÃ³a khÃ¡c cÃ³ tiá»m nÄƒng tá»‘t hÆ¡n."
    }
    if score >= 70: return full_advice["gold"] if metrics.get('growth_score', 0) > metrics.get('interest_score', 0) else full_advice["popular"]
    elif score >= 40: return full_advice["sustainable"] if metrics.get('slope', 0) > 0 else full_advice["evergreen"]
    else: return full_advice["saturated"] if metrics.get('avg_interest', 0) > 30 else full_advice["low_interest"]

# --- Giao diá»‡n ngÆ°á»i dÃ¹ng ---
st.title("ğŸ§  CÃ”NG Cá»¤ Cá» Váº¤N Cá»¦A LÃ VÄ‚N HIá»†P(KIOSOO)")
st.markdown("PhÃ¢n tÃ­ch, cháº¥m Ä‘iá»ƒm vÃ  Ä‘Æ°a ra lá»i khuyÃªn chiáº¿n lÆ°á»£c cho cÃ¡c chá»§ Ä‘á» cá»§a báº¡n.")
st.sidebar.header("âš™ï¸ TÃ¹y chá»n PhÃ¢n tÃ­ch")
timeframe = st.sidebar.selectbox("1. Khung thá»i gian", [('7 ngÃ y qua', 'now 7-d'), ('30 ngÃ y qua', 'today 1-m'), ('90 ngÃ y qua', 'today 3-m'), ('12 thÃ¡ng qua', 'today 12-m'), ('5 nÄƒm qua', 'today 5-y'), ('Tá»« 2004', 'all')], format_func=lambda x: x[0])[1]
gprop = st.sidebar.selectbox("2. Ná»n táº£ng tÃ¬m kiáº¿m", [('Web Search', ''), ('YouTube', 'youtube'), ('Google Images', 'images')], format_func=lambda x: x[0])[1]

with st.form("input_form"):
    col1, col2 = st.columns([3, 1])
    with col1: keywords_str = st.text_input("Nháº­p cÃ¡c tá»« khÃ³a (cÃ¡ch nhau báº±ng dáº¥u pháº©y)", "ná»“i chiÃªn khÃ´ng dáº§u, mÃ¡y Ã©p cháº­m, mÃ¡y lÃ m sá»¯a háº¡t")
    with col2: country_name = st.selectbox("Chá»n quá»‘c gia", options=list(SORTED_COUNTRIES.keys()), index=0); country_code = SORTED_COUNTRIES[country_name]
    submitted = st.form_submit_button("ğŸ’¡ PhÃ¢n tÃ­ch & TÆ° váº¥n")

if submitted:
    keywords = [kw.strip() for kw in keywords_str.split(',') if kw.strip()]
    if not keywords or not country_code: st.warning("Vui lÃ²ng nháº­p tá»« khÃ³a vÃ  chá»n quá»‘c gia.")
    else:
        with st.spinner("Äang phÃ¢n tÃ­ch vÃ  cháº¥m Ä‘iá»ƒm..."):
            interest_data, related_data, error = analyze_trends_data(keywords, country_code, timeframe, gprop)
        if error: st.error(error)
        elif interest_data is not None:
            st.header("1. Báº£ng Ä‘iá»ƒm Tiá»m nÄƒng")
            score_cards = st.columns(len(keywords)); all_metrics = {}
            for i, kw in enumerate(keywords):
                metrics = calculate_potential_score(interest_data.get(kw, pd.Series()), related_data.get(kw, {}))
                all_metrics[kw] = metrics
                with score_cards[i]: st.markdown(f"""<div style="background-color:{metrics['color']}; color:white; padding: 20px; border-radius: 10px; text-align: center; height: 180px; display: flex; flex-direction: column; justify-content: center;"><h4 style="color: white; margin-bottom: 5px;">{kw.upper()}</h4><h1 style="color: white; font-size: 3.5rem; margin: 0;">{metrics['score']}</h1><p style="color: white; margin-top: 5px;">{metrics['label']}</p></div>""", unsafe_allow_html=True)
            
            st.header("2. PhÃ¢n tÃ­ch & Lá»i khuyÃªn tá»« Cá»‘ váº¥n")
            for kw in keywords:
                with st.expander(f"**Xem phÃ¢n tÃ­ch chi tiáº¿t cho tá»« khÃ³a: '{kw}'**"):
                    metrics = all_metrics[kw]
                    if 'avg_interest' in metrics:
                        advice = generate_advice(kw, metrics)
                        st.markdown(advice)
                    else:
                        st.info(f"KhÃ´ng cÃ³ Ä‘á»§ dá»¯ liá»‡u xu hÆ°á»›ng cho tá»« khÃ³a '{kw}' Ä‘á»ƒ Ä‘Æ°a ra lá»i khuyÃªn chi tiáº¿t.")

            st.header("3. Biá»ƒu Ä‘á»“ so sÃ¡nh Má»©c Ä‘á»™ quan tÃ¢m")
            fig, ax = plt.subplots(figsize=(15, 7))
            for kw in keywords:
                if kw in interest_data.columns:
                    ax.plot(interest_data.index, interest_data[kw], label=kw)
            ax.set_title(f"So sÃ¡nh xu hÆ°á»›ng táº¡i '{country_name}'", fontsize=16); ax.legend(); ax.grid(True); st.pyplot(fig)

            st.header("4. Dá»¯ liá»‡u chi tiáº¿t (Insight TÄƒng trÆ°á»Ÿng)")
            for kw in keywords:
                if kw in related_data and related_data[kw]:
                    with st.expander(f"**Xem Insight vÃ  Video hÃ ng Ä‘áº§u cho: '{kw}'**"):
                        tab1, tab2, tab3 = st.tabs(["ğŸ“Š Truy váº¥n HÃ ng Ä‘áº§u", "ğŸ“ˆ Truy váº¥n TÄƒng trÆ°á»Ÿng", "ğŸ¬ Videos YouTube"])
                        with tab1: top_df = related_data[kw].get('top'); st.markdown("##### **CÃ¡c tá»« khÃ³a Ä‘Æ°á»£c tÃ¬m kiáº¿m nhiá»u nháº¥t liÃªn quan**"); st.dataframe(top_df)
                        with tab2: rising_df = all_metrics[kw].get('rising_df'); st.markdown("##### **CÃ¡c tá»« khÃ³a cÃ³ má»©c tÄƒng trÆ°á»Ÿng tÃ¬m kiáº¿m Ä‘á»™t phÃ¡**"); st.dataframe(rising_df)
                        with tab3:
                            st.markdown("##### **5 Video YouTube hÃ ng Ä‘áº§u cho tá»« khÃ³a liÃªn quan**")
                            if top_df is not None and not top_df.empty:
                                top_query = top_df['query'].iloc[0]
                                with st.spinner(f"Äang tÃ¬m video cho '{top_query}'..."): videos, error = search_youtube_videos_with_rotation(top_query)
                                if error: st.error(error)
                                elif videos:
                                    for video in videos:
                                        v_col1, v_col2 = st.columns([1, 4]);
                                        with v_col1: st.image(video['thumbnail'])
                                        with v_col2: st.markdown(f"**[{video['title']}]({video['url']})**"); st.caption(f"KÃªnh: {video['channel']}")
                                        st.markdown("---") 
                                else: st.info(f"KhÃ´ng tÃ¬m tháº¥y video nÃ o cho tá»« khÃ³a '{top_query}'.")
                            else: st.info("KhÃ´ng cÃ³ tá»« khÃ³a hÃ ng Ä‘áº§u Ä‘á»ƒ tÃ¬m kiáº¿m video.")

