# -*- coding: utf-8 -*-
"""
CÃ”NG Cá»¤ Cá» Váº¤N Cá»¦A LÃ VÄ‚N HIá»†P(KIOSOO)
XÃ¢y dá»±ng báº±ng Streamlit.
"""
import streamlit as st
from pytrends.request import TrendReq
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LinearRegression
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import time
from requests.exceptions import ReadTimeout

# --- Dá»¯ liá»‡u tÄ©nh ---
COUNTRIES = {
    'Vietnam': 'VN', 'United States': 'US', 'Japan': 'JP', 'South Korea': 'KR',
    'United Kingdom': 'GB', 'Germany': 'DE', 'France': 'FR', 'Canada': 'CA',
    'Australia': 'AU', 'India': 'IN', 'Brazil': 'BR', 'Russia': 'RU',
    'Thailand': 'TH', 'Singapore': 'SG', 'Malaysia': 'MY',
    'Indonesia': 'ID', 'Philippines': 'PH', 'Taiwan': 'TW', 'Hong Kong': 'HK',
    'Spain': 'ES', 'Portugal': 'PT'
}
SORTED_COUNTRIES = dict(sorted(COUNTRIES.items()))

# --- Cáº¥u hÃ¬nh trang web ---
st.set_page_config(page_title="CÃ”NG Cá»¤ Cá» Váº¤N Cá»¦A LÃ VÄ‚N HIá»†P(KIOSOO)", page_icon="ğŸ§ ", layout="wide")

# --- Khá»Ÿi táº¡o Session State Ä‘á»ƒ quáº£n lÃ½ API Key ---
if 'youtube_key_index' not in st.session_state:
    st.session_state.youtube_key_index = 0

# --- CÃ¡c hÃ m tÃ­nh toÃ¡n vÃ  tiá»‡n Ã­ch ---
# @st.cache_data(ttl=3600) # Táº¡m thá»i táº¯t cache Ä‘á»ƒ kiá»ƒm tra lá»—i 429 dá»… hÆ¡n, sau cÃ³ thá»ƒ báº­t láº¡i
def analyze_trends_data(keywords, country_code, timeframe, gprop):
    """
    HÃ€M ÄÆ¯á»¢C NÃ‚NG Cáº¤P Vá»šI LOGIC Tá»° Äá»˜NG THá»¬ Láº I (EXPONENTIAL BACKOFF)
    """
    retries = 3  # Sá»‘ láº§n thá»­ láº¡i tá»‘i Ä‘a
    delay = 1    # Thá»i gian chá» ban Ä‘áº§u (giÃ¢y)
    
    for i in range(retries):
        try:
            # ThÃªm timeout Ä‘á»ƒ trÃ¡nh á»©ng dá»¥ng bá»‹ treo
            pytrends = TrendReq(hl='en-US', tz=360, timeout=(10, 25)) 
            pytrends.build_payload(kw_list=keywords, timeframe=timeframe, geo=country_code, gprop=gprop)
            
            interest_df = pytrends.interest_over_time()
            related_queries = pytrends.related_queries()

            if interest_df.empty:
                return None, None, "KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u."
            
            interest_df.drop(columns=['isPartial'], inplace=True, errors='ignore')
            return interest_df, related_queries, None # Tráº£ vá» káº¿t quáº£ náº¿u thÃ nh cÃ´ng

        except ReadTimeout:
             if i < retries - 1:
                st.toast(f"Google Trends pháº£n há»“i cháº­m, Ä‘ang thá»­ láº¡i láº§n {i+1}/{retries-1}...")
                time.sleep(delay)
                delay *= 2 # Gáº¥p Ä‘Ã´i thá»i gian chá»
             else:
                return None, None, "Lá»—i: Google Trends khÃ´ng pháº£n há»“i ká»‹p thá»i. Vui lÃ²ng thá»­ láº¡i sau."

        except Exception as e:
            # Chá»‰ thá»­ láº¡i náº¿u gáº·p lá»—i 429
            if 'response with code 429' in str(e):
                if i < retries - 1:
                    st.toast(f"Bá»‹ giá»›i háº¡n truy cáº­p, Ä‘ang thá»­ láº¡i sau {delay} giÃ¢y...")
                    time.sleep(delay)
                    delay *= 2 # Gáº¥p Ä‘Ã´i thá»i gian chá» cho láº§n thá»­ tiáº¿p theo
                else:
                    # Náº¿u thá»­ háº¿t sá»‘ láº§n mÃ  váº«n lá»—i
                    return None, None, f"Lá»—i: Google Trends Ä‘ang táº¡m thá»i giá»›i háº¡n truy cáº­p. Vui lÃ²ng thá»­ láº¡i sau Ã­t phÃºt. (Code: 429)"
            else:
                # Náº¿u lÃ  lá»—i khÃ¡c, bÃ¡o lá»—i ngay láº­p tá»©c
                return None, None, f"ÄÃ£ xáº£y ra lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}"
    
    return None, None, "ÄÃ£ thá»­ láº¡i nhiá»u láº§n nhÆ°ng khÃ´ng thÃ nh cÃ´ng."


def search_youtube_videos_with_rotation(query):
    api_keys_str = st.secrets.get("YOUTUBE_API_KEYS", "")
    if not api_keys_str:
        return None, "Lá»—i cáº¥u hÃ¬nh: Vui lÃ²ng thÃªm YOUTUBE_API_KEYS vÃ o Streamlit Secrets."
    
    api_keys = [key.strip() for key in api_keys_str.split(',')]
    start_index = st.session_state.youtube_key_index
    
    for i in range(len(api_keys)):
        current_key_index = (start_index + i) % len(api_keys)
        api_key = api_keys[current_key_index]
        
        try:
            youtube = build('youtube', 'v3', developerKey=api_key)
            request = youtube.search().list(q=query, part='snippet', maxResults=5, type='video', order='relevance')
            response = request.execute()
            st.session_state.youtube_key_index = (current_key_index + 1) % len(api_keys)
            videos = [{'id': item['id']['videoId'], 'title': item['snippet']['title'], 'channel': item['snippet']['channelTitle'], 'thumbnail': item['snippet']['thumbnails']['high']['url'], 'url': f'https://www.youtube.com/watch?v={item["id"]["videoId"]}'} for item in response.get('items', [])]
            return videos, None
        except HttpError as e:
            error_details = e.error_details
            is_quota_error = any(detail.get('reason') in ['quotaExceeded', 'dailyLimitExceeded'] for detail in error_details) if error_details else False
            if is_quota_error:
                print(f"Key {current_key_index + 1} Ä‘Ã£ háº¿t quota. Äang chuyá»ƒn sang key tiáº¿p theo...")
                continue
            else:
                return None, f"Lá»—i API vá»›i Key {current_key_index + 1}: {e}. Vui lÃ²ng kiá»ƒm tra láº¡i key."
        except Exception as e:
            return None, f"ÄÃ£ xáº£y ra lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}"
    return None, "Táº¥t cáº£ cÃ¡c API key Ä‘á»u Ä‘Ã£ háº¿t háº¡n ngáº¡ch hoáº·c khÃ´ng há»£p lá»‡."

def calculate_potential_score(interest_series, related_queries_data):
    if interest_series.empty or interest_series.sum() == 0:
        return {'score': 0, 'label': "KhÃ´ng cÃ³ dá»¯ liá»‡u", 'color': "#6c757d"}
    avg_interest = interest_series.mean()
    avg_interest_score = min((avg_interest / 80), 1) * 30 
    X = np.arange(len(interest_series)).reshape(-1, 1)
    y = interest_series.values
    model = LinearRegression().fit(X, y)
    slope = model.coef_[0]
    normalized_slope = (slope / (avg_interest + 1e-6)) * 100
    trend_score = 10 + normalized_slope
    trend_score = np.clip(trend_score, 0, 20)
    interest_score = avg_interest_score + trend_score
    growth_score = 0
    rising_df = related_queries_data.get('rising')
    if rising_df is not None and not rising_df.empty:
        def process_rising_value(val):
            if isinstance(val, str) and 'Breakout' in val: return 10000
            numeric_val = pd.to_numeric(str(val).replace('+','').replace('%','').replace(',',''), errors='coerce')
            return numeric_val if pd.notnull(numeric_val) else 0
        rising_df['value_numeric'] = rising_df['value'].apply(process_rising_value)
        num_rising_score = min(len(rising_df) / 10, 1) * 25
        avg_growth_score = min(rising_df['value_numeric'].mean() / 1000, 1) * 25
        growth_score = num_rising_score + avg_growth_score
    total_score = int(interest_score + growth_score)
    if total_score >= 70: label, color = 'Tiá»m nÄƒng cao', '#28a745'
    elif total_score >= 40: label, color = 'Trung bÃ¬nh', '#ffc107'
    else: label, color = 'BÃ£o hÃ²a / Cáº¡nh tranh cao', '#dc3545'
    return {'score': total_score, 'label': label, 'color': color, 'interest_score': interest_score, 'growth_score': growth_score, 'slope': slope, 'avg_interest': avg_interest, 'rising_df': rising_df}

def generate_advice(kw, metrics):
    score = metrics['score']
    full_advice = {
        "gold": f"**ğŸŸ¢ ÄÃ‚Y LÃ€ Má»˜T CÆ  Há»˜I VÃ€NG!** ...",
        "popular": f"**ğŸŸ¢ CHá»¦ Äá»€ ÄANG Ráº¤T THá»ŠNH HÃ€NH!** ...",
        "sustainable": f"**ğŸŸ¡ CÆ  Há»˜I NGÃCH Bá»€N Vá»®NG.** ...",
        "evergreen": f"**ğŸŸ¡ CHá»¦ Äá»€ 'EVERGREEN' Cáº¦N TÃŒM NGÃCH.** ...",
        "saturated": f"**ğŸ”´ Cáº¨N TRá»ŒNG - THá»Š TRÆ¯á»œNG BÃƒO HÃ’A.** ...",
        "low_interest": f"**ğŸ”´ CHá»¦ Äá»€ ÃT QUAN TÃ‚M.** ..."
    } # Giá»¯ ngáº¯n gá»n Ä‘á»ƒ táº­p trung vÃ o logic
    if score >= 70: return full_advice["gold"] if metrics.get('growth_score', 0) > metrics.get('interest_score', 0) else full_advice["popular"]
    elif score >= 40: return full_advice["sustainable"] if metrics.get('slope', 0) > 0 else full_advice["evergreen"]
    else: return full_advice["saturated"] if metrics.get('avg_interest', 0) > 30 else full_advice["low_interest"]

# --- Giao diá»‡n ngÆ°á»i dÃ¹ng ---
st.title("ğŸ§  CÃ”NG Cá»¤ Cá» Váº¤N Cá»¦A LÃ VÄ‚N HIá»†P(KIOSOO)")
st.markdown("PhÃ¢n tÃ­ch, cháº¥m Ä‘iá»ƒm vÃ  Ä‘Æ°a ra lá»i khuyÃªn chiáº¿n lÆ°á»£c cho cÃ¡c chá»§ Ä‘á» cá»§a báº¡n.")
st.sidebar.header("âš™ï¸ TÃ¹y chá»n PhÃ¢n tÃ­ch")
timeframe = st.sidebar.selectbox("1. Khung thá»i gian", [('7 ngÃ y qua', 'now 7-d'), ('30 ngÃ y qua', 'today 1-m'), ('90 ngÃ y qua', 'today 3-m'), ('12 thÃ¡ng qua', 'today 12-m'), ('5 nÄƒm qua', 'today 5-y'), ('Tá»« 2004', 'all')], format_func=lambda x: x[0])[1]
gprop = st.sidebar.selectbox("2. Ná»n táº£ng tÃ¬m kiáº¿m", [('Web Search', ''), ('YouTube', 'youtube'), ('Google Images', 'images')], format_func=lambda x: x[0])[1]

with st.form("input_form"):
    col1, col2 = st.columns([3, 1])
    with col1: keywords_str = st.text_input("Nháº­p cÃ¡c tá»« khÃ³a (cÃ¡ch nhau báº±ng dáº¥u pháº©y)", "ná»“i chiÃªn khÃ´ng dáº§u, mÃ¡y Ã©p cháº­m, mÃ¡y lÃ m sá»¯a háº¡t")
    with col2: country_name = st.selectbox("Chá»n quá»‘c gia", options=list(SORTED_COUNTRIES.keys()), index=0); country_code = SORTED_COUNTRIES[country_name]
    submitted = st.form_submit_button("ğŸ’¡ PhÃ¢n tÃ­ch & TÆ° váº¥n")

if submitted:
    keywords = [kw.strip() for kw in keywords_str.split(',') if kw.strip()]
    if not keywords or not country_code: st.warning("Vui lÃ²ng nháº­p tá»« khÃ³a vÃ  chá»n quá»‘c gia.")
    else:
        with st.spinner("Äang phÃ¢n tÃ­ch vÃ  cháº¥m Ä‘iá»ƒm..."):
            interest_data, related_data, error = analyze_trends_data(keywords, country_code, timeframe, gprop)
        if error: st.error(error)
        elif interest_data is not None:
            st.header("1. Báº£ng Ä‘iá»ƒm Tiá»m nÄƒng")
            # Code hiá»ƒn thá»‹ giá»¯ nguyÃªn
            score_cards = st.columns(len(keywords)); all_metrics = {}
            for i, kw in enumerate(keywords):
                metrics = calculate_potential_score(interest_data.get(kw, pd.Series()), related_data.get(kw, {}))
                all_metrics[kw] = metrics
                with score_cards[i]: st.markdown(f"""<div style="background-color:{metrics['color']}; color:white; padding: 20px; border-radius: 10px; text-align: center; height: 180px; display: flex; flex-direction: column; justify-content: center;"><h4 style="color: white; margin-bottom: 5px;">{kw.upper()}</h4><h1 style="color: white; font-size: 3.5rem; margin: 0;">{metrics['score']}</h1><p style="color: white; margin-top: 5px;">{metrics['label']}</p></div>""", unsafe_allow_html=True)
            
            st.header("2. PhÃ¢n tÃ­ch & Lá»i khuyÃªn tá»« Cá»‘ váº¥n")
            for kw in keywords:
                with st.expander(f"**Xem phÃ¢n tÃ­ch chi tiáº¿t cho tá»« khÃ³a: '{kw}'**"):
                    metrics = all_metrics[kw]
                    if 'avg_interest' in metrics:
                        advice = generate_advice(kw, metrics)
                        st.markdown(advice)
                    else:
                        st.info(f"KhÃ´ng cÃ³ Ä‘á»§ dá»¯ liá»‡u xu hÆ°á»›ng cho tá»« khÃ³a '{kw}' Ä‘á»ƒ Ä‘Æ°a ra lá»i khuyÃªn chi tiáº¿t.")

            st.header("3. Biá»ƒu Ä‘á»“ so sÃ¡nh Má»©c Ä‘á»™ quan tÃ¢m")
            # Code hiá»ƒn thá»‹ giá»¯ nguyÃªn
            fig, ax = plt.subplots(figsize=(15, 7))
            for kw in keywords:
                if kw in interest_data.columns:
                    ax.plot(interest_data.index, interest_data[kw], label=kw)
            ax.set_title(f"So sÃ¡nh xu hÆ°á»›ng táº¡i '{country_name}'", fontsize=16); ax.legend(); ax.grid(True); st.pyplot(fig)

            st.header("4. Dá»¯ liá»‡u chi tiáº¿t (Insight TÄƒng trÆ°á»Ÿng)")
            # Code hiá»ƒn thá»‹ giá»¯ nguyÃªn
            for kw in keywords:
                if kw in related_data and related_data[kw]:
                    with st.expander(f"**Xem Insight vÃ  Video hÃ ng Ä‘áº§u cho: '{kw}'**"):
                        tab1, tab2, tab3 = st.tabs(["ğŸ“Š Truy váº¥n HÃ ng Ä‘áº§u", "ğŸ“ˆ Truy váº¥n TÄƒng trÆ°á»Ÿng", "ğŸ¬ Videos YouTube"])
                        with tab1: top_df = related_data[kw].get('top'); st.markdown("##### **CÃ¡c tá»« khÃ³a Ä‘Æ°á»£c tÃ¬m kiáº¿m nhiá»u nháº¥t liÃªn quan**"); st.dataframe(top_df)
                        with tab2: rising_df = all_metrics[kw].get('rising_df'); st.markdown("##### **CÃ¡c tá»« khÃ³a cÃ³ má»©c tÄƒng trÆ°á»Ÿng tÃ¬m kiáº¿m Ä‘á»™t phÃ¡**"); st.dataframe(rising_df)
                        with tab3:
                            st.markdown("##### **5 Video YouTube hÃ ng Ä‘áº§u cho tá»« khÃ³a liÃªn quan**")
                            if top_df is not None and not top_df.empty:
                                top_query = top_df['query'].iloc[0]
                                with st.spinner(f"Äang tÃ¬m video cho '{top_query}'..."): videos, error = search_youtube_videos_with_rotation(top_query)
                                if error: st.error(error)
                                elif videos:
                                    for video in videos:
                                        v_col1, v_col2 = st.columns([1, 4]);
                                        with v_col1: st.image(video['thumbnail'])
                                        with v_col2: st.markdown(f"**[{video['title']}]({video['url']})**"); st.caption(f"KÃªnh: {video['channel']}")
                                        st.markdown("---") 
                                else: st.info(f"KhÃ´ng tÃ¬m tháº¥y video nÃ o cho tá»« khÃ³a '{top_query}'.")
                            else: st.info("KhÃ´ng cÃ³ tá»« khÃ³a hÃ ng Ä‘áº§u Ä‘á»ƒ tÃ¬m kiáº¿m video.")
```

---
### ## Giáº£i phÃ¡p 2: Sá»­ dá»¥ng Proxy xoay vÃ²ng (Rotating Proxies) - Tá»‘t nháº¥t & ChuyÃªn nghiá»‡p (CÃ³ phÃ­)

ÄÃ¢y lÃ  giáº£i phÃ¡p triá»‡t Ä‘á»ƒ nháº¥t, Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi cÃ¡c há»‡ thá»‘ng chuyÃªn nghiá»‡p.

* **Logic:** Thay vÃ¬ táº¥t cáº£ yÃªu cáº§u Ä‘á»u xuáº¥t phÃ¡t tá»« má»™t Ä‘á»‹a chá»‰ IP duy nháº¥t cá»§a mÃ¡y chá»§ Streamlit, chÃºng ta sáº½ sá»­ dá»¥ng má»™t dá»‹ch vá»¥ proxy Ä‘á»ƒ "che giáº¥u" vÃ  thay Ä‘á»•i Ä‘á»‹a chá»‰ IP cho má»—i yÃªu cáº§u. Tá»« gÃ³c nhÃ¬n cá»§a Google, cÃ¡c yÃªu cáº§u nÃ y Ä‘áº¿n tá»« hÃ ng trÄƒm Ä‘á»‹a Ä‘iá»ƒm khÃ¡c nhau trÃªn tháº¿ giá»›i, khiáº¿n viá»‡c phÃ¡t hiá»‡n vÃ  cháº·n trá»Ÿ nÃªn gáº§n nhÆ° khÃ´ng thá»ƒ. 

* **Æ¯u Ä‘iá»ƒm:**
    * Hiá»‡u quáº£ gáº§n nhÆ° 100% trong viá»‡c chá»‘ng lá»—i 429.
    * Tá»‘c Ä‘á»™ cÃ³ thá»ƒ nhanh hÆ¡n vÃ¬ cÃ¡c dá»‹ch vá»¥ proxy thÆ°á»ng Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a.
    * LÃ  giáº£i phÃ¡p cÃ³ thá»ƒ má»Ÿ rá»™ng (scalable) khi á»©ng dá»¥ng cá»§a báº¡n cÃ³ nhiá»u ngÆ°á»i dÃ¹ng.

* **NhÆ°á»£c Ä‘iá»ƒm:**
    * **CÃ³ chi phÃ­.** Báº¡n sáº½ pháº£i tráº£ tiá»n hÃ ng thÃ¡ng cho má»™t dá»‹ch vá»¥ cung cáº¥p proxy (vÃ­ dá»¥: Bright Data, ScraperAPI, Smartproxy).

* **CÃ¡ch triá»ƒn khai (VÃ­ dá»¥):**
    1.  ÄÄƒng kÃ½ má»™t dá»‹ch vá»¥ proxy vÃ  láº¥y thÃ´ng tin káº¿t ná»‘i (host, port, username, password).
    2.  LÆ°u cÃ¡c thÃ´ng tin nÃ y vÃ o **Secrets** cá»§a Streamlit.
    3.  Cáº¥u hÃ¬nh `pytrends` Ä‘á»ƒ sá»­ dá»¥ng proxy Ä‘Ã³.

    ```python
    # VÃ­ dá»¥ cÃ¡ch cáº¥u hÃ¬nh pytrends vá»›i proxy
    
    # Láº¥y thÃ´ng tin tá»« secrets
    proxy_host = st.secrets["proxy"]["host"]
    proxy_port = st.secrets["proxy"]["port"]
    proxy_user = st.secrets["proxy"]["user"]
    proxy_pass = st.secrets["proxy"]["password"]

    # Táº¡o chuá»—i proxy
    proxy_url = f"http://{proxy_user}:{proxy_pass}@{proxy_host}:{proxy_port}"
    
    # Táº¡o dictionary proxies
    proxies = {
       'http': proxy_url,
       'https': proxy_url,
    }

    # Truyá»n vÃ o pytrends
    pytrends = TrendReq(hl='en-US', tz=360, requests_args={'proxies': proxies})
    

